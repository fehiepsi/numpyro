{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real-world datasets often contain many missing values. In those situations, we have to either remove those missing data (also known as \"complete case\") or replace them by some values. Though using complete case is pretty straightforward, it is only applicable when the number of missing entries is so small that throwing away those entries would not affect much the power of the analysis we are conducting on the data. The second strategy, also known as [imputation](https://en.wikipedia.org/wiki/Imputation_(statistics)), is more applicable and will be our focus in this tutorial.\n",
    "\n",
    "Probably the most popular way to perform imputation is to fill a missing value with the mean, median, or mode of its corresponding feature. In that case, we implicitly assume that the feature containing missing values has no correlation with the remaining features of our dataset. This is a pretty strong assumption and might not be true in general. In addition, it does not encode any uncertainty that we might put on those values. In below, we will construct a *Bayesian* setting to resolve those issues. In particular, given a model on the dataset, we will\n",
    "\n",
    "+ create a generative model for the feature with missing value\n",
    "+ and consider missing values as unobserved latent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, we need some imports\n",
    "import os\n",
    "\n",
    "from IPython.display import set_matplotlib_formats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as onp\n",
    "import pandas as pd\n",
    "\n",
    "from jax import numpy as np, ops, random\n",
    "from jax.scipy.special import expit\n",
    "\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.infer import MCMC, NUTS, Predictive\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "if \"NUMPYRO_SPHINXBUILD\" in os.environ:\n",
    "    set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is taken from the competition [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic) hosted on [kaggle](https://www.kaggle.com/). It contains information of passengers in the [Titanic accident](https://en.wikipedia.org/wiki/Sinking_of_the_RMS_Titanic) such as name, age, gender,... And our target is to predict if a person is more likely to survive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"https://raw.githubusercontent.com/agconti/kaggle-titanic/master/data/train.csv\")\n",
    "train_df.info()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the data info, we know that there are missing data at `Age`, `Cabin`, and `Embarked` columns. Although `Cabin` is an important feature (because the position of a cabin in the ship can affect the chance of people in that cabin to survive), we will skip it in this tutorial for simplicity. In the datset, there are many categorical columns and two numerical columns `Age` and `Fare`. Let's first look at the distribution of those categorical columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    549\n",
      "1    342\n",
      "Name: Survived, dtype: int64\n",
      "\n",
      "3    491\n",
      "1    216\n",
      "2    184\n",
      "Name: Pclass, dtype: int64\n",
      "\n",
      "male      577\n",
      "female    314\n",
      "Name: Sex, dtype: int64\n",
      "\n",
      "0    608\n",
      "1    209\n",
      "2     28\n",
      "4     18\n",
      "3     16\n",
      "8      7\n",
      "5      5\n",
      "Name: SibSp, dtype: int64\n",
      "\n",
      "0    678\n",
      "1    118\n",
      "2     80\n",
      "5      5\n",
      "3      5\n",
      "4      4\n",
      "6      1\n",
      "Name: Parch, dtype: int64\n",
      "\n",
      "S    644\n",
      "C    168\n",
      "Q     77\n",
      "Name: Embarked, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in [\"Survived\", \"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Embarked\"]:\n",
    "    print(train_df[col].value_counts(), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will merge rare groups in `SibSp` and `Parch` columns together. In addition, we'll fill 2 missing entries in `Embarked` by the mode `S`. Note that we can make a generative model for those missing entries in `Embarked` but let's skip doing so for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = train_df.copy()\n",
    "d.SibSp.clip(0, 1, inplace=True)\n",
    "d.Parch.clip(0, 2, inplace=True)\n",
    "d.Embarked.fillna(\"S\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking closer at the data, we can observe that each name contains a title. We know that age is correlated with the title of the name: e.g. those with Mrs. would be older than those with `Miss.` (in average) so it might be good to create that feature. The distribution of titles is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr.          517\n",
       "Miss.        182\n",
       "Mrs.         125\n",
       "Master.       40\n",
       "Dr.            7\n",
       "Rev.           6\n",
       "Major.         2\n",
       "Mlle.          2\n",
       "Col.           2\n",
       "Lady.          1\n",
       "Ms.            1\n",
       "Mme.           1\n",
       "Capt.          1\n",
       "Don.           1\n",
       "Sir.           1\n",
       "Jonkheer.      1\n",
       "the            1\n",
       "Name: Name, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.Name.str.split(\", \").str.get(1).str.split(\" \").str.get(0).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make a new column `Title`, where rare titles are merged into one group `Misc.`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[\"Title\"] = d.Name.str.split(\", \").str.get(1).str.split(\" \").str.get(0).apply(\n",
    "    lambda x: x if x in [\"Mr.\", \"Miss.\", \"Mrs.\", \"Master.\"] else \"Misc.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it is ready to turn the dataframe, which includes categorical values, into numpy arrays. We also perform standardization (a good practice for regression models) for `Age` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_cat = pd.CategoricalDtype(categories=[\"Mr.\", \"Miss.\", \"Mrs.\", \"Master.\", \"Misc.\"], ordered=True)\n",
    "embarked_cat = pd.CategoricalDtype(categories=[\"S\", \"C\", \"Q\"], ordered=True)\n",
    "age_mean, age_std = d.Age.mean(), d.Age.std()\n",
    "data = dict(age=d.Age.pipe(lambda x: (x - age_mean) / age_std).values,\n",
    "            pclass=d.Pclass.values - 1,\n",
    "            title=d.Title.astype(title_cat).cat.codes.values,\n",
    "            sex=(d.Sex == \"male\").astype(int).values,\n",
    "            sibsp=d.SibSp.values,\n",
    "            parch=d.Parch.values,\n",
    "            embarked=d.Embarked.astype(embarked_cat).cat.codes.values,\n",
    "            survived=d.Survived.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we would like to talk a bit about how to define improper priors in NumPyro. Consider the following logistic regression model,\n",
    "```python\n",
    "def model(x, y):\n",
    "    a = numpyro.sample(\"a\", dist.Normal(0, 1))\n",
    "    b = numpyro.param(\"b\", dist.Normal(0, 1))\n",
    "    sigma = numpyro.sample(\"sigma\", dist.Exponential(1))\n",
    "    numpyro.sample(\"obs\", dist.Normal(a + b * x, sigma), obs=y)\n",
    "```\n",
    ". There we have some priors on sites `a`, `b`, and `sigma`. Now, assume that there is no apriori information on those sites, how can we define and get posterior samples of `a`, `b`, and `sigma`? In NumPyro, we can do it with `numpyro.param` primitives. An MCMC kernel will treat all `param` sites as they are having improper priors. For example, a corresponding linear regression model with no prior information is\n",
    "```python\n",
    "def model(x, y):\n",
    "    a = numpyro.param(\"a\", 0)\n",
    "    b = numpyro.param(\"b\", 1)\n",
    "    sigma = numpyro.param(\"sigma\", 1, constraint=constraints.positive)\n",
    "    numpyro.sample(\"obs\", dist.Normal(a + b * x, sigma), obs=y)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another remark is: in MCMC context, the following models\n",
    "```python\n",
    "def model1():\n",
    "    a = numpyro.sample(\"a\", dist.Normal(0, 1))\n",
    "```\n",
    "and\n",
    "```python\n",
    "def model2():\n",
    "    a = numpyro.param(\"a\", 0)\n",
    "    numpyro.sample(\"a_obs\", dist.Normal(0, 1), obs=a)\n",
    "```\n",
    "are equivalent because both of them have\n",
    "+ the same latent sites `a`,\n",
    "+ and the same log densities `dist.Normal(0, 1).log_prob(a)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With those remarks in mind, we are ready to define a logistic regression model to predict survival chance given passengers' information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(age, pclass, title, sex, sibsp, parch, embarked, survived=None):\n",
    "    b_pclass = numpyro.sample(\"b_Pclass\", dist.Normal(0, 1), sample_shape=(3,))\n",
    "    b_title = numpyro.sample(\"b_Title\", dist.Normal(0, 1), sample_shape=(5,))\n",
    "    b_sex = numpyro.sample(\"b_Sex\", dist.Normal(0, 1), sample_shape=(2,))\n",
    "    b_sibsp = numpyro.sample(\"b_SibSp\", dist.Normal(0, 1), sample_shape=(2,))\n",
    "    b_parch = numpyro.sample(\"b_Parch\", dist.Normal(0, 1), sample_shape=(3,))\n",
    "    b_embarked = numpyro.sample(\"b_Embarked\", dist.Normal(0, 1), sample_shape=(3,))\n",
    "\n",
    "    # impute age by Title\n",
    "    age_mu = numpyro.sample(\"age_mu\", dist.Normal(0, 1), sample_shape=(5,))\n",
    "    age_mu = age_mu[title]\n",
    "    age_sigma = numpyro.sample(\"age_sigma\", dist.Normal(0, 1), sample_shape=(5,))\n",
    "    age_sigma = age_sigma[title]\n",
    "    age_isnan = onp.isnan(age)\n",
    "    age_nanidx = onp.nonzero(age_isnan)[0]\n",
    "    if survived is not None:\n",
    "        age_impute = numpyro.param(\"age_impute\", np.zeros(age_isnan.sum()))\n",
    "    else:  # we are making prediction\n",
    "        age_impute = numpyro.sample(\"age_impute\", dist.Normal(age_mu[age_nanidx], age_sigma[age_nanidx]))\n",
    "    age = ops.index_update(age, age_nanidx, age_impute)\n",
    "    numpyro.sample(\"age\", dist.Normal(age_mu, age_sigma), obs=age)\n",
    "\n",
    "    a = numpyro.sample(\"a\", dist.Normal(0, 1))\n",
    "    b_age = numpyro.sample(\"b_Age\", dist.Normal(0, 1))\n",
    "    logits = a + b_age * age\n",
    "\n",
    "    logits = logits + b_title[title] + b_pclass[pclass] + b_sex[sex] \\\n",
    "        + b_sibsp[sibsp] + b_parch[parch] + b_embarked[embarked]\n",
    "    if survived is None:\n",
    "        probs = expit(logits)\n",
    "        # record `probs` value in prediction\n",
    "        numpyro.sample(\"probs\", dist.Delta(probs))\n",
    "    numpyro.sample(\"survived\", dist.Bernoulli(logits=logits), obs=survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the model, the prior for `age` is `dist.Normal(age_mu, age_sigma)`, where the values of `age_mu` and `age_sigma` depend on `title`. Because there are missing values in `age`, we will encode those missing values in the latent parameter `age_impute`. Then we can replace `NaN` entries in `age` with the vector `age_impute`. Under the hood, similar to `model2` in the above remark, `age_impute` will have prior `dist.Normal(age_mu, age_sigma)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use MCMC with NUTS kernel to sample both regression coefficients and imputed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [00:37<00:00, 53.79it/s, 63 steps of size 6.75e-02. acc. prob=0.94] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                     mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "              a      0.11      0.83      0.10     -1.37      1.35    806.48      1.00\n",
      "  age_impute[0]      0.24      0.84      0.22     -1.12      1.58   1921.09      1.00\n",
      "  age_impute[1]     -0.12      0.87     -0.18     -1.58      1.28   1992.55      1.00\n",
      "  age_impute[2]      0.37      0.81      0.39     -0.90      1.75   1914.70      1.00\n",
      "  age_impute[3]      0.25      0.83      0.24     -1.23      1.47   1601.95      1.00\n",
      "  age_impute[4]     -0.69      0.90     -0.67     -2.03      0.90   2558.34      1.00\n",
      "  age_impute[5]      0.22      0.89      0.21     -1.16      1.71   2686.84      1.00\n",
      "  age_impute[6]      0.41      0.80      0.41     -1.00      1.56   1813.22      1.00\n",
      "  age_impute[7]     -0.64      0.88     -0.65     -2.12      0.75   2097.52      1.00\n",
      "  age_impute[8]     -0.14      0.90     -0.13     -1.69      1.18   2614.57      1.00\n",
      "  age_impute[9]      0.24      0.87      0.24     -1.17      1.67   2896.45      1.00\n",
      " age_impute[10]      0.19      0.89      0.22     -1.30      1.57   2268.71      1.00\n",
      " age_impute[11]      0.22      0.87      0.22     -1.18      1.63   1686.34      1.00\n",
      " age_impute[12]     -0.64      0.87     -0.64     -1.96      0.91   1576.48      1.00\n",
      " age_impute[13]      0.23      0.85      0.26     -1.12      1.72   1942.64      1.00\n",
      " age_impute[14]     -0.00      0.88      0.02     -1.48      1.33   2139.59      1.00\n",
      " age_impute[15]      0.40      0.86      0.43     -1.06      1.76   1625.81      1.00\n",
      " age_impute[16]     -1.73      0.26     -1.72     -2.19     -1.35   1738.17      1.00\n",
      " age_impute[17]      0.20      0.87      0.19     -1.19      1.72   2518.32      1.00\n",
      " age_impute[18]      0.20      0.85      0.17     -1.03      1.70   1587.02      1.00\n",
      " age_impute[19]     -0.65      0.88     -0.67     -2.09      0.81   1385.00      1.00\n",
      " age_impute[20]      0.22      0.93      0.23     -1.31      1.74   1643.83      1.00\n",
      " age_impute[21]      0.20      0.90      0.21     -1.24      1.65   1822.79      1.00\n",
      " age_impute[22]      0.21      0.90      0.20     -1.37      1.56   2304.03      1.00\n",
      " age_impute[23]     -0.14      0.92     -0.17     -1.73      1.24   1807.93      1.00\n",
      " age_impute[24]     -0.71      0.96     -0.68     -2.28      0.83   1796.97      1.00\n",
      " age_impute[25]      0.15      0.90      0.12     -1.30      1.58   2187.04      1.00\n",
      " age_impute[26]      0.22      0.92      0.19     -1.14      1.87   1965.79      1.00\n",
      " age_impute[27]     -0.72      0.88     -0.70     -2.33      0.60   1743.09      1.00\n",
      " age_impute[28]      0.55      0.72      0.56     -0.56      1.71   1526.90      1.00\n",
      " age_impute[29]      0.22      0.87      0.24     -1.29      1.56   1844.96      1.00\n",
      " age_impute[30]      0.21      0.92      0.17     -1.14      1.85   2195.27      1.00\n",
      " age_impute[31]     -1.71      0.25     -1.72     -2.13     -1.33   1320.21      1.00\n",
      " age_impute[32]      0.43      0.83      0.40     -0.89      1.78   1734.26      1.00\n",
      " age_impute[33]      0.31      0.82      0.33     -0.86      1.82   1930.75      1.00\n",
      " age_impute[34]     -1.72      0.26     -1.72     -2.14     -1.27   1451.74      1.00\n",
      " age_impute[35]     -0.46      0.93     -0.44     -1.93      1.01   1326.19      1.00\n",
      " age_impute[36]      0.27      0.89      0.30     -1.28      1.71   1637.11      1.00\n",
      " age_impute[37]      0.33      0.84      0.34     -0.93      1.88   1992.16      1.00\n",
      " age_impute[38]      0.37      0.80      0.36     -0.95      1.59   2047.52      1.00\n",
      " age_impute[39]      0.21      0.87      0.18     -1.29      1.54   2384.21      1.00\n",
      " age_impute[40]     -0.65      0.84     -0.65     -1.96      0.72   2232.39      1.00\n",
      " age_impute[41]      0.21      0.89      0.20     -1.20      1.58   1573.71      1.00\n",
      " age_impute[42]      0.20      0.85      0.21     -1.05      1.64   2410.50      1.00\n",
      " age_impute[43]      0.21      0.89      0.22     -1.11      1.84   2876.14      1.00\n",
      " age_impute[44]     -0.43      0.87     -0.43     -1.87      0.98   2136.42      1.00\n",
      " age_impute[45]     -0.34      0.88     -0.34     -1.77      1.00   1779.16      1.00\n",
      " age_impute[46]     -0.33      0.92     -0.30     -1.78      1.12   1843.68      1.00\n",
      " age_impute[47]     -0.69      0.93     -0.69     -2.13      0.82   1447.42      1.00\n",
      " age_impute[48]      0.20      0.90      0.20     -1.20      1.70   1826.54      1.00\n",
      " age_impute[49]      0.38      0.81      0.37     -0.98      1.70   2997.68      1.00\n",
      " age_impute[50]      0.25      0.85      0.27     -1.25      1.61   1768.55      1.00\n",
      " age_impute[51]     -0.33      0.92     -0.35     -1.89      1.22   2220.50      1.00\n",
      " age_impute[52]      0.33      0.85      0.32     -1.19      1.55   1548.29      1.00\n",
      " age_impute[53]     -0.67      0.84     -0.67     -2.08      0.60   2516.06      1.00\n",
      " age_impute[54]      0.22      0.84      0.26     -1.15      1.54   2214.24      1.00\n",
      " age_impute[55]      0.34      0.85      0.33     -0.92      1.77   1951.31      1.00\n",
      " age_impute[56]      0.35      0.87      0.34     -0.95      1.88   2040.68      1.00\n",
      " age_impute[57]     -0.03      0.87     -0.03     -1.57      1.29   1530.06      1.00\n",
      " age_impute[58]     -0.64      0.90     -0.62     -2.29      0.66   2448.03      1.00\n",
      " age_impute[59]     -0.15      0.89     -0.14     -1.68      1.21   1485.33      1.00\n",
      " age_impute[60]     -0.61      0.92     -0.61     -2.15      0.83   3187.11      1.00\n",
      " age_impute[61]      0.22      0.88      0.26     -1.08      1.74   1481.11      1.00\n",
      " age_impute[62]     -0.58      0.82     -0.57     -1.98      0.67   1670.35      1.00\n",
      " age_impute[63]      0.22      0.93      0.22     -1.34      1.73   2599.12      1.00\n",
      " age_impute[64]     -0.68      0.90     -0.66     -2.11      0.75   2207.13      1.00\n",
      " age_impute[65]      0.40      0.79      0.39     -0.86      1.73   1671.20      1.00\n",
      " age_impute[66]      0.22      0.86      0.21     -1.11      1.77   2307.28      1.00\n",
      " age_impute[67]      0.29      0.83      0.29     -1.05      1.64   1611.72      1.00\n",
      " age_impute[68]      0.32      0.90      0.31     -1.22      1.70   1561.23      1.00\n",
      " age_impute[69]      0.22      0.87      0.23     -1.14      1.62   1791.63      1.00\n",
      " age_impute[70]     -0.66      0.87     -0.64     -2.11      0.74   1541.89      1.00\n",
      " age_impute[71]     -0.64      0.87     -0.62     -2.06      0.69   1356.21      1.00\n",
      " age_impute[72]      0.22      0.91      0.23     -1.14      1.84   1527.82      1.00\n",
      " age_impute[73]      0.39      0.78      0.39     -0.95      1.52   1540.51      1.00\n",
      " age_impute[74]     -0.66      0.86     -0.66     -1.96      0.83   1628.41      1.00\n",
      " age_impute[75]      0.39      0.81      0.38     -1.06      1.64   1936.16      1.00\n",
      " age_impute[76]      0.19      0.93      0.20     -1.30      1.75   2022.21      1.00\n",
      " age_impute[77]      0.24      0.85      0.23     -1.07      1.58   2242.48      1.00\n",
      " age_impute[78]     -0.39      0.91     -0.37     -1.91      1.04   2382.79      1.00\n",
      " age_impute[79]      0.23      0.89      0.24     -1.26      1.61   1297.09      1.00\n",
      " age_impute[80]      0.22      0.94      0.24     -1.30      1.72   2614.20      1.00\n",
      " age_impute[81]      0.22      0.87      0.22     -1.15      1.74   3580.77      1.00\n",
      " age_impute[82]      0.60      0.83      0.56     -0.73      1.94   1898.26      1.00\n",
      " age_impute[83]      0.23      0.86      0.25     -1.38      1.51   1907.98      1.00\n",
      " age_impute[84]      0.21      0.86      0.21     -1.22      1.61   1877.39      1.00\n",
      " age_impute[85]      0.23      0.88      0.25     -1.21      1.65   1430.03      1.00\n",
      " age_impute[86]      0.33      0.78      0.36     -0.94      1.57   2085.25      1.00\n",
      " age_impute[87]     -0.12      0.86     -0.12     -1.43      1.36   2685.16      1.00\n",
      " age_impute[88]      0.19      0.88      0.21     -1.16      1.61   1682.09      1.00\n",
      " age_impute[89]      0.23      0.89      0.24     -1.16      1.75   1567.66      1.00\n",
      " age_impute[90]      0.42      0.74      0.43     -0.79      1.58   1865.63      1.00\n",
      " age_impute[91]      0.23      0.89      0.24     -1.13      1.67   2596.80      1.00\n",
      " age_impute[92]      0.21      0.83      0.20     -1.08      1.64   1294.90      1.00\n",
      " age_impute[93]      0.27      0.89      0.27     -1.22      1.58   2449.02      1.00\n",
      " age_impute[94]      0.23      0.85      0.23     -1.18      1.62   2505.80      1.00\n",
      " age_impute[95]      0.24      0.84      0.25     -0.96      1.88   2359.77      1.00\n",
      " age_impute[96]      0.34      0.84      0.34     -0.93      1.87   1772.40      1.00\n",
      " age_impute[97]      0.26      0.90      0.27     -1.24      1.68   2480.66      1.00\n",
      " age_impute[98]     -0.41      0.90     -0.42     -1.81      1.06   1797.77      1.00\n",
      " age_impute[99]      0.20      0.83      0.17     -1.11      1.57   1751.21      1.00\n",
      "age_impute[100]      0.23      0.87      0.22     -1.26      1.58   1604.39      1.00\n",
      "age_impute[101]      0.21      0.88      0.20     -1.29      1.61   2169.50      1.00\n",
      "age_impute[102]     -0.31      0.86     -0.29     -1.70      1.04   1452.68      1.00\n",
      "age_impute[103]     -0.01      0.89     -0.00     -1.55      1.37   1772.85      1.00\n",
      "age_impute[104]      0.23      0.83      0.24     -1.02      1.56   3154.03      1.00\n",
      "age_impute[105]      0.22      0.87      0.22     -1.15      1.65   1935.28      1.00\n",
      "age_impute[106]      0.23      0.94      0.22     -1.27      1.83   1882.97      1.00\n",
      "age_impute[107]      0.23      0.88      0.25     -1.26      1.66   2322.21      1.00\n",
      "age_impute[108]      0.32      0.85      0.30     -0.97      1.84   2648.58      1.00\n",
      "age_impute[109]      0.24      0.85      0.25     -1.11      1.63   1862.12      1.00\n",
      "age_impute[110]      0.31      0.77      0.34     -0.96      1.56   1499.92      1.00\n",
      "age_impute[111]      0.21      0.86      0.20     -1.30      1.49   2293.42      1.00\n",
      "age_impute[112]     -0.05      0.89     -0.08     -1.34      1.49   1939.51      1.00\n",
      "age_impute[113]      0.20      0.84      0.20     -1.26      1.48   2010.63      1.00\n",
      "age_impute[114]      0.36      0.87      0.31     -0.85      1.95   2266.52      1.00\n",
      "age_impute[115]      0.20      0.87      0.25     -1.36      1.43   1929.38      1.00\n",
      "age_impute[116]      0.19      0.84      0.17     -1.12      1.59   2408.40      1.00\n",
      "age_impute[117]     -0.31      0.92     -0.30     -1.81      1.11   1572.06      1.00\n",
      "age_impute[118]      0.22      0.85      0.26     -1.15      1.62   2455.65      1.00\n",
      "age_impute[119]     -0.62      0.91     -0.59     -2.02      1.05   1773.66      1.00\n",
      "age_impute[120]      0.63      0.77      0.60     -0.66      1.81   1764.77      1.00\n",
      "age_impute[121]      0.22      0.92      0.24     -1.28      1.69   1707.88      1.00\n",
      "age_impute[122]      0.23      0.84      0.22     -1.08      1.57   1939.73      1.00\n",
      "age_impute[123]     -0.40      0.93     -0.39     -1.82      1.17   1589.04      1.00\n",
      "age_impute[124]     -0.63      0.92     -0.64     -2.10      0.89   1995.77      1.00\n",
      "age_impute[125]      0.22      0.90      0.22     -1.26      1.56   2206.98      1.00\n",
      "age_impute[126]      0.24      0.86      0.24     -1.16      1.57   1958.00      1.00\n",
      "age_impute[127]      0.32      0.82      0.30     -1.13      1.64   1833.16      1.00\n",
      "age_impute[128]      0.18      0.90      0.20     -1.19      1.69   1782.16      1.00\n",
      "age_impute[129]     -0.68      0.87     -0.69     -2.08      0.73   2708.33      1.00\n",
      "age_impute[130]      0.22      0.86      0.22     -1.20      1.58   1896.47      1.00\n",
      "age_impute[131]      0.22      0.86      0.23     -1.21      1.60   1612.25      1.00\n",
      "age_impute[132]      0.35      0.90      0.36     -1.18      1.83   1717.00      1.00\n",
      "age_impute[133]      0.23      0.93      0.25     -1.24      1.79   2479.39      1.00\n",
      "age_impute[134]     -0.09      0.88     -0.10     -1.53      1.46   1632.02      1.00\n",
      "age_impute[135]      0.20      0.87      0.22     -1.07      1.74   2392.53      1.00\n",
      "age_impute[136]      0.20      0.85      0.21     -1.25      1.46   2669.17      1.00\n",
      "age_impute[137]     -0.65      0.88     -0.64     -2.31      0.59   2069.43      1.00\n",
      "age_impute[138]      0.16      0.85      0.18     -1.09      1.67   1442.56      1.00\n",
      "age_impute[139]      0.20      0.93      0.18     -1.21      1.77   2139.53      1.00\n",
      "age_impute[140]      0.38      0.80      0.36     -0.88      1.69   1254.09      1.00\n",
      "age_impute[141]      0.26      0.88      0.26     -1.30      1.56   2039.79      1.00\n",
      "age_impute[142]     -0.34      0.87     -0.36     -1.61      1.28   2520.56      1.00\n",
      "age_impute[143]     -0.13      0.90     -0.12     -1.56      1.35   2221.29      1.00\n",
      "age_impute[144]     -0.68      0.88     -0.66     -2.17      0.68   2445.99      1.00\n",
      "age_impute[145]     -1.74      0.26     -1.74     -2.21     -1.35   2503.50      1.00\n",
      "age_impute[146]      0.30      0.88      0.33     -1.12      1.72   1615.44      1.00\n",
      "age_impute[147]      0.23      0.88      0.23     -1.25      1.68   1181.32      1.00\n",
      "age_impute[148]     -0.66      0.82     -0.68     -1.93      0.74   1751.04      1.00\n",
      "age_impute[149]      0.24      0.82      0.25     -1.10      1.57   2029.21      1.00\n",
      "age_impute[150]      0.20      0.78      0.21     -1.03      1.53   1942.48      1.00\n",
      "age_impute[151]      0.20      0.86      0.20     -1.21      1.54   1830.77      1.00\n",
      "age_impute[152]     -0.00      0.86      0.01     -1.42      1.39   2637.93      1.00\n",
      "age_impute[153]      0.22      0.82      0.22     -1.18      1.50   1919.90      1.00\n",
      "age_impute[154]      1.09      0.95      1.08     -0.52      2.55   2599.22      1.00\n",
      "age_impute[155]      0.20      0.87      0.21     -1.20      1.52   2007.58      1.00\n",
      "age_impute[156]      0.26      0.85      0.24     -1.09      1.68   1912.32      1.00\n",
      "age_impute[157]      0.21      0.90      0.23     -1.26      1.62   2375.45      1.00\n",
      "age_impute[158]      0.22      0.86      0.20     -1.06      1.69   1929.90      1.00\n",
      "age_impute[159]      0.18      0.87      0.20     -1.27      1.63   1962.54      1.00\n",
      "age_impute[160]      0.22      0.89      0.21     -1.33      1.63   1979.78      1.00\n",
      "age_impute[161]     -0.43      0.86     -0.45     -2.01      0.86   2155.49      1.00\n",
      "age_impute[162]      0.37      0.85      0.36     -0.96      1.79   1976.94      1.00\n",
      "age_impute[163]      0.33      0.85      0.34     -1.09      1.66   1755.25      1.00\n",
      "age_impute[164]      0.22      0.84      0.24     -1.15      1.59   1835.75      1.00\n",
      "age_impute[165]      0.19      0.88      0.19     -1.23      1.50   2021.01      1.00\n",
      "age_impute[166]     -0.12      0.81     -0.10     -1.43      1.17   2219.02      1.00\n",
      "age_impute[167]      0.20      0.86      0.19     -1.21      1.55   1266.26      1.00\n",
      "age_impute[168]      0.23      0.86      0.24     -1.34      1.55   1976.63      1.00\n",
      "age_impute[169]      0.04      0.84      0.07     -1.22      1.59   1799.22      1.00\n",
      "age_impute[170]      0.21      0.86      0.20     -1.41      1.44   1855.86      1.00\n",
      "age_impute[171]      0.42      0.80      0.41     -1.00      1.65   2508.68      1.00\n",
      "age_impute[172]      0.20      0.88      0.19     -1.20      1.75   2620.80      1.00\n",
      "age_impute[173]     -0.49      0.89     -0.48     -2.02      0.85   3034.76      1.00\n",
      "age_impute[174]      0.22      0.85      0.19     -1.01      1.79   2300.51      1.00\n",
      "age_impute[175]      0.17      0.81      0.20     -1.16      1.40   1264.28      1.00\n",
      "age_impute[176]     -0.45      0.94     -0.45     -1.82      1.29   2633.67      1.00\n",
      "      age_mu[0]      0.19      0.04      0.19      0.12      0.26   1078.03      1.00\n",
      "      age_mu[1]     -0.54      0.07     -0.55     -0.66     -0.43   1644.39      1.00\n",
      "      age_mu[2]      0.42      0.07      0.42      0.29      0.54   1541.12      1.00\n",
      "      age_mu[3]     -1.73      0.04     -1.73     -1.80     -1.66   1498.24      1.00\n",
      "      age_mu[4]      0.85      0.17      0.85      0.57      1.14   2678.98      1.00\n",
      "   age_sigma[0]      0.88      0.03      0.88      0.83      0.93    822.49      1.00\n",
      "   age_sigma[1]      0.90      0.05      0.90      0.81      0.98   1125.53      1.00\n",
      "   age_sigma[2]      0.79      0.06      0.79      0.70      0.88   1301.18      1.00\n",
      "   age_sigma[3]      0.26      0.03      0.25      0.21      0.32    966.39      1.00\n",
      "   age_sigma[4]      0.94      0.14      0.92      0.71      1.14   1143.33      1.00\n",
      "          b_Age     -0.44      0.13     -0.44     -0.66     -0.23   1590.74      1.00\n",
      "  b_Embarked[0]     -0.24      0.57     -0.22     -1.15      0.66    644.01      1.00\n",
      "  b_Embarked[1]      0.34      0.58      0.35     -0.59      1.30    632.49      1.00\n",
      "  b_Embarked[2]      0.08      0.59      0.07     -0.88      1.00    677.19      1.00\n",
      "     b_Parch[0]      0.49      0.55      0.47     -0.38      1.45    536.09      1.00\n",
      "     b_Parch[1]      0.15      0.56      0.14     -0.77      1.04    653.95      1.00\n",
      "     b_Parch[2]     -0.45      0.56     -0.46     -1.43      0.41    561.68      1.00\n",
      "    b_Pclass[0]      1.20      0.56      1.20      0.27      2.11    492.11      1.00\n",
      "    b_Pclass[1]      0.05      0.56      0.08     -0.96      0.88    481.79      1.00\n",
      "    b_Pclass[2]     -1.18      0.56     -1.16     -2.05     -0.21    439.55      1.00\n",
      "       b_Sex[0]      1.12      0.70      1.12     -0.09      2.21    966.55      1.00\n",
      "       b_Sex[1]     -1.08      0.73     -1.07     -2.21      0.14    907.79      1.00\n",
      "     b_SibSp[0]      0.26      0.64      0.29     -0.79      1.29    753.15      1.00\n",
      "     b_SibSp[1]     -0.19      0.63     -0.19     -1.14      0.93    686.48      1.00\n",
      "     b_Title[0]     -0.96      0.54     -0.96     -1.81     -0.10    809.10      1.00\n",
      "     b_Title[1]     -0.35      0.58     -0.36     -1.33      0.58    779.43      1.00\n",
      "     b_Title[2]      0.53      0.59      0.53     -0.41      1.51    743.57      1.00\n",
      "     b_Title[3]      1.48      0.59      1.49      0.41      2.40    876.72      1.00\n",
      "     b_Title[4]     -0.69      0.61     -0.70     -1.60      0.40   1125.29      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "mcmc = MCMC(NUTS(model), 1000, 1000)\n",
    "mcmc.run(random.PRNGKey(0), **data)\n",
    "mcmc.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To double check that the assumption \"age is correlated with title\" is reasonable, let's look at the infered age by title. Recall that we performed standarization on `age`, so here we need to scale back to original domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mr.': 32.412045,\n",
       " 'Miss.': 21.793062,\n",
       " 'Mrs.': 35.81341,\n",
       " 'Master.': 4.6275177,\n",
       " 'Misc.': 42.0792}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_by_title = age_mean + age_std * mcmc.get_samples()[\"age_mu\"].mean(axis=0)\n",
    "dict(zip(title_cat.categories, age_by_title))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The infered result confirms our assumption that `Age` is correlated with `Title`:\n",
    "\n",
    "+ those with `Master.` title has pretty small age (in other words, they are children in the ship) comparing to the other groups,\n",
    "+ those with `Mrs.` title have larger age than those with `Miss.` title (in average).\n",
    "\n",
    "We can also see that the result is similar to the actual statistical mean of `Age` given `Title` in our training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title\n",
       "Master.     4.574167\n",
       "Misc.      42.384615\n",
       "Miss.      21.773973\n",
       "Mr.        32.368090\n",
       "Mrs.       35.898148\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.groupby(\"Title\")[\"Age\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good, we have many information about the regression coefficients together with imputed values and their uncertainties. Let's inspect those results a bit:\n",
    "\n",
    "+ The mean value `-0.44` of `b_Age` implies that those with smaller ages have better chance to survive.\n",
    "+ The mean value `(1.11, -1.07)` of `b_Sex` implies that female passengers have higher chance to survive than male passengers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In NumPyro, we can use [Predictive](http://num.pyro.ai/en/stable/utilities.html#numpyro.infer.util.Predictive) utility for making predictions from posterior samples. Let's check how well the model performs on the training dataset. In this case, we will predict the chance to survive of each passenger (in other words, the `probs` values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(0.8260382, dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior = mcmc.get_samples().copy()\n",
    "survived = data.pop(\"survived\")\n",
    "survived_probs = Predictive(model, posterior).get_samples(random.PRNGKey(1), **data)[\"probs\"]\n",
    "((survived_probs.mean(axis=0) >= 0.5).astype(np.uint8) == survived).sum() / survived.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a pretty good result using a simple logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comes to the test set, which also contains missing data in `Age` feature. We can't use `age_impute` from posterior samples because it is specific to the training set. So we need to marginalize them from the joint posterior distribution first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior.pop(\"age_impute\", None);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will use the generative model for `age`, which is `dist.Normal(age_mu, age_sigma)`, to generate missing values for the test set:\n",
    "```python\n",
    "def model(age, ...):\n",
    "    ...\n",
    "    age_isnan = onp.isnan(age)\n",
    "    age_nanidx = onp.nonzero(age_isnan)[0]\n",
    "    age_impute = numpyro.sample(\"age_impute\", dist.Normal(age_mu[age_nanidx], age_sigma[age_nanidx]))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All ingredients are ready for making prediction. We just need to perform the same data transformation process as the train set and use `Predictive` utility as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"https://raw.githubusercontent.com/agconti/kaggle-titanic/master/data/test.csv\")\n",
    "d = test_df.copy()\n",
    "d[\"Title\"] = d.Name.str.split(\", \").str.get(1).str.split(\" \").str.get(0).apply(\n",
    "    lambda x: x if x in [\"Mr.\", \"Miss.\", \"Mrs.\", \"Master.\"] else \"Misc.\")\n",
    "test_data = dict(age=d.Age.pipe(lambda x: (x - age_mean) / age_std).values,\n",
    "                 pclass=d.Pclass.values - 1,\n",
    "                 title=d.Title.astype(title_cat).cat.codes.values,\n",
    "                 sex=(d.Sex == \"male\").astype(int).values,\n",
    "                 sibsp=d.SibSp.clip(0, 1).values,\n",
    "                 parch=d.Parch.clip(0, 2).values,\n",
    "                 embarked=d.Embarked.astype(embarked_cat).cat.codes.values)\n",
    "\n",
    "survived_probs = Predictive(model, posterior).get_samples(random.PRNGKey(2), **test_data)[\"probs\"]\n",
    "d[\"Survived\"] = (survived_probs.mean(axis=0) >= 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "onp.random.seed(0)\n",
    "num_passengers = 15\n",
    "sample_idx = onp.random.choice(range(d.shape[0]), num_passengers, replace=False)\n",
    "sample_idx.sort()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(survived_probs.mean(0)[sample_idx], \"o\")\n",
    "plt.xticks(ticks=range(num_passengers), labels=d.PassengerId.iloc[sample_idx], rotation=0)\n",
    "\n",
    "p_mu = np.mean(survived_probs, axis=0)[sample_idx]\n",
    "p_ci = np.percentile(survived_probs, q=(5, 95), axis=0)[:, sample_idx]\n",
    "for i in range(num_passengers):\n",
    "    plt.plot(np.repeat(i, 2), p_ci[:, i], \"k\", lw=1)\n",
    "\n",
    "plt.xlabel(\"PassengerID\")\n",
    "plt.ylabel(\"Chance to Survive\")\n",
    "plt.title(\"Chance to survive (with 90% CI) of {} random passengers in the test data\".format(num_passengers))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. McElreath, R. (2016). Statistical Rethinking: A Bayesian Course with Examples in R and Stan.\n",
    "2. Kaggle competition: [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
